name: Comprehensive Quality Assurance Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Daily quality monitoring at 6 AM UTC
    - cron: '0 6 * * *'

env:
  PYTHON_VERSION: '3.9'

jobs:
  quality-gate-validation:
    name: ğŸ”’ Quality Gate Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v3
        with:
          fetch-depth: 2  # Need previous commit for regression detection

      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: ğŸ”’ Ring 1 Validation (BLOCKING)
        id: ring1_validation
        run: |
          echo "::group::Ring 1 - Enforced Coverage Tests"
          python test_runner.py --ring 1 --verbose
          echo "::endgroup::"
        continue-on-error: false

      - name: ğŸ“„ Ring 2 Validation (OPTIONAL)
        id: ring2_validation
        run: |
          echo "::group::Ring 2 - PDF Processing Pipeline"
          python test_runner.py --ring 2 --verbose || echo "Ring 2 optional validation"
          echo "::endgroup::"
        continue-on-error: true

      - name: âš¡ Ring 3 Validation (FLEXIBLE)
        id: ring3_validation
        run: |
          echo "::group::Ring 3 - Advanced Functionality"
          python test_runner.py --ring 3 --verbose || echo "Ring 3 flexible validation"
          echo "::endgroup::"
        continue-on-error: true

      - name: ğŸ“Š Quality Metrics Collection
        run: |
          echo "::group::Quality Metrics Tracking"
          python quality_monitor.py --track
          echo "::endgroup::"

      - name: âš ï¸ Regression Detection
        id: regression_check
        run: |
          echo "::group::Quality Regression Analysis"
          python quality_monitor.py --regressions || echo "::warning::Quality regressions detected"
          echo "::endgroup::"
        continue-on-error: true

      - name: ğŸ“‹ Generate Quality Report
        run: |
          python quality_monitor.py --report quality_report_${{ github.sha }}.html --days 7
          python test_runner.py --all --performance --report comprehensive_report_${{ github.sha }}.json

      - name: ğŸ“ Upload Quality Reports
        uses: actions/upload-artifact@v3
        with:
          name: quality-reports-${{ github.sha }}
          path: |
            quality_report_*.html
            comprehensive_report_*.json
            quality_metrics.db
          retention-days: 30

      - name: ğŸ’¬ Quality Summary Comment (PR only)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            try {
              const reportFile = `comprehensive_report_${{ github.sha }}.json`;
              const report = JSON.parse(fs.readFileSync(reportFile, 'utf8'));

              const summary = report.summary;
              const passRate = summary.pass_rate.toFixed(1);
              const totalTests = summary.total_tests;
              const duration = summary.total_duration.toFixed(2);

              const body = `## ğŸ§ª Quality Assurance Report

              **Overall Status:** ${summary.overall_success ? 'âœ… PASS' : 'âŒ FAIL'}

              ### ğŸ“Š Test Execution Summary
              - **Pass Rate:** ${passRate}% (${summary.total_passed}/${totalTests} tests)
              - **Execution Time:** ${duration}s
              - **Rings Validated:** ${summary.successful_rings}/${summary.total_rings}

              ### ğŸ” Ring Breakdown
              ${Object.entries(report.rings).map(([ringId, ringData]) =>
                `- **Ring ${ringId}**: ${ringData.tests_passed}/${ringData.tests_collected} tests (${ringData.success ? 'âœ…' : 'âŒ'})`
              ).join('\\n')}

              ### âš¡ Performance Metrics
              - **Speed:** ${report.performance?.overall_tests_per_second?.toFixed(1) || 'N/A'} tests/sec
              - **Average Ring Duration:** ${report.performance?.avg_ring_duration?.toFixed(2) || 'N/A'}s

              [ğŸ“ Download detailed reports](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
            } catch (error) {
              console.log('Could not generate quality comment:', error.message);
            }

  daily-quality-monitoring:
    name: ğŸ“ˆ Daily Quality Monitoring
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    timeout-minutes: 20

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v3

      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: ğŸ“Š Comprehensive Quality Analysis
        run: |
          echo "::group::Daily Quality Tracking"
          python quality_monitor.py --track
          echo "::endgroup::"

          echo "::group::30-Day Trend Analysis"
          python quality_monitor.py --analyze --days 30
          echo "::endgroup::"

          echo "::group::Quality Dashboard Generation"
          python quality_monitor.py --report daily_quality_dashboard.html --days 30
          echo "::endgroup::"

      - name: ğŸ” Long-term Regression Detection
        run: |
          echo "::group::14-Day Regression Analysis"
          python quality_monitor.py --regressions || echo "::warning::Long-term regressions detected"
          echo "::endgroup::"

      - name: ğŸ“ Archive Daily Reports
        uses: actions/upload-artifact@v3
        with:
          name: daily-quality-report-${{ github.run_id }}
          path: |
            daily_quality_dashboard.html
            quality_metrics.db
          retention-days: 90

      - name: ğŸš¨ Quality Alert Notification
        if: failure()
        run: |
          echo "::error::Daily quality monitoring detected critical issues"
          # Add notification logic here (Slack, email, etc.)

  performance-benchmarking:
    name: âš¡ Performance Benchmarking
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    timeout-minutes: 25

    steps:
      - name: ğŸ“¥ Checkout Code
        uses: actions/checkout@v3

      - name: ğŸ Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: âš¡ Performance Benchmarking
        run: |
          echo "::group::Performance Baseline Execution"
          for i in {1..3}; do
            echo "Run $i/3:"
            python test_runner.py --all --performance --report perf_run_$i.json
          done
          echo "::endgroup::"

      - name: ğŸ“Š Performance Analysis
        run: |
          echo "::group::Performance Trend Analysis"
          python quality_monitor.py --track
          python quality_monitor.py --analyze --days 7
          echo "::endgroup::"

      - name: ğŸ“ Upload Performance Data
        uses: actions/upload-artifact@v3
        with:
          name: performance-benchmarks-${{ github.sha }}
          path: |
            perf_run_*.json
            quality_metrics.db
          retention-days: 60

  quality-gate-summary:
    name: ğŸ† Quality Gate Summary
    runs-on: ubuntu-latest
    needs: [quality-gate-validation]
    if: always()

    steps:
      - name: ğŸ“Š Quality Gate Results
        run: |
          echo "## ğŸ¯ Quality Gate Summary"
          echo "- Ring 1 (Enforced): ${{ needs.quality-gate-validation.outputs.ring1_status || 'Unknown' }}"
          echo "- Ring 2 (Optional): ${{ needs.quality-gate-validation.outputs.ring2_status || 'Unknown' }}"
          echo "- Ring 3 (Flexible): ${{ needs.quality-gate-validation.outputs.ring3_status || 'Unknown' }}"

          if [ "${{ needs.quality-gate-validation.result }}" = "success" ]; then
            echo "âœ… Overall Quality Gate: PASSED"
            echo "ğŸš€ Deployment approved based on quality metrics"
          else
            echo "âŒ Overall Quality Gate: FAILED"
            echo "ğŸš« Deployment blocked - review quality issues"
          fi
