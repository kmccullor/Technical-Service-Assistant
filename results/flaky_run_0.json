{
  "timestamp": "2025-10-01T16:21:04.428752",
  "rings": {
    "1": {
      "ring_id": 1,
      "name": "Ring 1 - Enforced Coverage",
      "success": true,
      "tests_collected": 17,
      "tests_passed": 17,
      "tests_failed": 0,
      "expected_tests": 17,
      "coverage_achieved": 95.0,
      "coverage_target": 95,
      "meets_coverage_target": true,
      "duration": 2.0952982902526855,
      "enforcement": "strict",
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.9.21, pytest-8.3.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /home/kmccullor/Projects/Technical-Service-Assistant\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, Faker-37.8.0, mock-3.11.1, cov-5.0.0, asyncio-0.21.1\nasyncio: mode=strict\ncollecting ... collected 17 items\n\ntests/test_phase4a_coverage_targets.py::test_classification_parquet_roundtrip PASSED [  5%]\ntests/test_phase4a_coverage_targets.py::test_confidence_calibrator_low_sample_and_richness PASSED [ 11%]\ntests/test_phase4a_coverage_targets.py::test_priority_and_quality_edge_cases PASSED [ 17%]\ntests/test_phase4a_coverage_targets.py::test_spec_miner_parentheses_fallback_and_range PASSED [ 23%]\ntests/test_phase4a_coverage_targets.py::test_process_discovery_hybrid_and_relation_absence PASSED [ 29%]\ntests/test_phase4a_coverage_targets.py::test_knowledge_extractor_snapshot_persistence PASSED [ 35%]\ntests/test_phase4a_coverage_targets.py::test_async_classifier_small_richness_difference PASSED [ 41%]\ntests/test_phase4a_coverage_targets.py::test_classification_persistence_error_and_validation PASSED [ 47%]\ntests/test_phase4a_coverage_targets.py::test_quick_test_harness_executes PASSED [ 52%]\ntests/test_phase4a_coverage_targets.py::test_spec_miner_invalid_unit_followed_by_new_spec PASSED [ 58%]\ntests/test_phase4a_coverage_targets.py::test_classification_append_and_empty_stats PASSED [ 64%]\ntests/test_phase4a_coverage_targets.py::test_knowledge_extractor_load_entities_no_file PASSED [ 70%]\ntests/test_phase4a_coverage_targets.py::test_confidence_calibrator_upper_bound PASSED [ 76%]\ntests/test_phase4a_coverage_targets.py::test_process_discovery_duplicate_indices_normalization PASSED [ 82%]\ntests/test_phase4a_coverage_targets.py::test_relation_extractor_positive_path PASSED [ 88%]\ntests/test_phase4a_coverage_targets.py::test_spec_miner_second_chance_parentheses_unit PASSED [ 94%]\ntests/test_phase4a_coverage_targets.py::test_knowledge_extractor_snapshot_statistics PASSED [100%]\n\n---------- coverage: platform linux, python 3.9.21-final-0 -----------\nName                                 Stmts   Miss  Cover   Missing\n------------------------------------------------------------------\nphase4a_document_classification.py     235     12    95%   224-227, 231, 389, 402, 407-408, 410-412\nphase4a_knowledge_extraction.py        272     25    91%   203, 215-216, 219, 222-223, 238-244, 248, 261, 313-314, 321, 330-331, 334-335, 348-349, 381, 505\n------------------------------------------------------------------\nTOTAL                                  507     37    93%\nCoverage HTML written to dir htmlcov\nCoverage XML written to file coverage.xml\n\nFAIL Required test coverage of 95% not reached. Total coverage: 92.70%\n\n============================== 17 passed in 0.79s ==============================\n",
      "stderr": "",
      "return_code": 1
    },
    "2": {
      "ring_id": 2,
      "name": "Ring 2 - Comprehensive Pipeline",
      "success": true,
      "tests_collected": 30,
      "tests_passed": 30,
      "tests_failed": 0,
      "expected_tests": 31,
      "coverage_achieved": 0.0,
      "coverage_target": 85,
      "meets_coverage_target": null,
      "duration": 2.984511613845825,
      "enforcement": "optional",
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.9.21, pytest-8.3.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /home/kmccullor/Projects/Technical-Service-Assistant\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, Faker-37.8.0, mock-3.11.1, cov-5.0.0, asyncio-0.21.1\nasyncio: mode=strict\ncollecting ... collected 30 items\n\ntests/test_pdf_processor_chunking.py::test_chunk_text_empty_input PASSED [  3%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_single_sentence PASSED [  6%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_multi_paragraph_with_overlap PASSED [ 10%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_start_index_offset PASSED [ 13%]\ntests/test_pdf_processor_chunking.py::test_chunk_images_metadata_integrity PASSED [ 16%]\ntests/test_pdf_processor_chunking.py::test_chunk_images_long_paths PASSED [ 20%]\ntests/test_pdf_processor_chunking.py::test_chunk_images_special_characters_in_paths PASSED [ 23%]\ntests/test_pdf_processor_chunking.py::test_chunk_images_different_extensions PASSED [ 26%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_unicode_handling PASSED [ 30%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_very_long_text PASSED [ 33%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_special_characters PASSED [ 36%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_empty_paragraphs PASSED [ 40%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_whitespace_only_paragraphs PASSED [ 43%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_single_word_sentences PASSED [ 46%]\ntests/test_pdf_processor_chunking.py::test_chunk_text_no_sentence_endings PASSED [ 50%]\ntests/test_pdf_processor_database.py::test_get_db_connection_success PASSED [ 53%]\ntests/test_pdf_processor_database.py::test_get_db_connection_error PASSED [ 56%]\ntests/test_pdf_processor_database.py::test_remove_existing_document_found PASSED [ 60%]\ntests/test_pdf_processor_database.py::test_remove_existing_document_not_found PASSED [ 63%]\ntests/test_pdf_processor_database.py::test_remove_existing_document_database_error PASSED [ 66%]\ntests/test_pdf_processor_database.py::test_insert_document_with_categorization_new_document PASSED [ 70%]\ntests/test_pdf_processor_database.py::test_insert_document_with_categorization_existing_document PASSED [ 73%]\ntests/test_pdf_processor_database.py::test_insert_document_with_categorization_error PASSED [ 76%]\ntests/test_pdf_processor_database.py::test_insert_document_chunks_with_categorization_success PASSED [ 80%]\ntests/test_pdf_processor_database.py::test_insert_document_chunks_empty_chunks PASSED [ 83%]\ntests/test_pdf_processor_database.py::test_insert_document_chunks_embedding_failures PASSED [ 86%]\ntests/test_pdf_processor_database.py::test_insert_document_chunks_duplicate_detection PASSED [ 90%]\ntests/test_pdf_processor_database.py::test_insert_ingestion_metrics_success PASSED [ 93%]\ntests/test_pdf_processor_database.py::test_insert_ingestion_metrics_error PASSED [ 96%]\ntests/test_pdf_processor_database.py::test_insert_ingestion_metrics_calculations PASSED [100%]WARNING: Failed to generate report: No data to report.\n\n\n\n---------- coverage: platform linux, python 3.9.21-final-0 -----------\n\n\n============================== 30 passed in 1.58s ==============================\n",
      "stderr": "/home/kmccullor/.local/lib/python3.9/site-packages/coverage/inorout.py:521: CoverageWarning: Module phase4a_document_classification was never imported. (module-not-imported)\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/home/kmccullor/.local/lib/python3.9/site-packages/coverage/inorout.py:521: CoverageWarning: Module phase4a_knowledge_extraction was never imported. (module-not-imported)\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/home/kmccullor/.local/lib/python3.9/site-packages/coverage/control.py:945: CoverageWarning: No data was collected. (no-data-collected)\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n/home/kmccullor/.local/lib/python3.9/site-packages/pytest_cov/plugin.py:339: CovReportWarning: Failed to generate report: No data to report.\n\n  self.cov_controller.finish()\n",
      "return_code": 0
    },
    "3": {
      "ring_id": 3,
      "name": "Ring 3 - Advanced Functionality",
      "success": true,
      "tests_collected": 74,
      "tests_passed": 66,
      "tests_failed": 0,
      "expected_tests": 76,
      "coverage_achieved": 0.0,
      "coverage_target": 80,
      "meets_coverage_target": null,
      "duration": 1.9069421291351318,
      "enforcement": "flexible",
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.9.21, pytest-8.3.2, pluggy-1.6.0 -- /usr/bin/python3\ncachedir: .pytest_cache\nrootdir: /home/kmccullor/Projects/Technical-Service-Assistant\nconfigfile: pyproject.toml\nplugins: anyio-4.10.0, Faker-37.8.0, mock-3.11.1, cov-5.0.0, asyncio-0.21.1\nasyncio: mode=strict\ncollecting ... collected 74 items\n\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_import_exceptions_module PASSED [  1%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_base_exception_creation PASSED [  2%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_exception_with_error_code PASSED [  4%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_pdf_processing_error FAILED [  5%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_embedding_generation_error FAILED [  6%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_database_error FAILED [  8%]\ntests/test_utils_comprehensive.py::TestCustomExceptions::test_exception_serialization PASSED [  9%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_decorator_basic PASSED [ 10%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_decorator_with_name FAILED [ 12%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_context_manager PASSED [ 13%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_memory_profiling_decorator PASSED [ 14%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_system_metrics_collection PASSED [ 16%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_timing_accuracy FAILED [ 17%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_prometheus_integration PASSED [ 18%]\ntests/test_utils_comprehensive.py::TestMonitoringUtils::test_error_tracking_in_monitoring PASSED [ 20%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_query_analysis_basic PASSED [ 21%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_query_analysis_technical_terms PASSED [ 22%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_query_enhancement_for_search PASSED [ 24%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_semantic_similarity_scoring PASSED [ 25%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_hybrid_search_algorithm PASSED [ 27%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_bm25_search_implementation PASSED [ 28%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_query_expansion_techniques PASSED [ 29%]\ntests/test_utils_comprehensive.py::TestEnhancedSearch::test_search_result_reranking PASSED [ 31%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_setup_logging_basic PASSED [ 32%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_setup_logging_with_level FAILED [ 33%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_structured_logging_format PASSED [ 35%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_json_logging_formatter PASSED [ 36%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_logging_with_context PASSED [ 37%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_error_logging_with_traceback PASSED [ 39%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_log_rotation_configuration FAILED [ 40%]\ntests/test_utils_comprehensive.py::TestLoggingConfiguration::test_logging_performance_impact FAILED [ 41%]\ntests/test_utils_comprehensive.py::TestUtilsIntegration::test_monitoring_with_logging PASSED [ 43%]\ntests/test_utils_comprehensive.py::TestUtilsIntegration::test_enhanced_search_with_monitoring PASSED [ 44%]\ntests/test_utils_comprehensive.py::TestUtilsIntegration::test_exception_handling_with_logging PASSED [ 45%]\ntests/test_utils_comprehensive.py::TestUtilsIntegration::test_comprehensive_utils_workflow PASSED [ 47%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_import_orchestrator_module PASSED [ 48%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_initialization PASSED [ 50%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_single_step_reasoning PASSED [ 51%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_multi_step_reasoning PASSED [ 52%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_with_context PASSED [ 54%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_timeout_handling PASSED [ 55%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_error_recovery PASSED [ 56%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningOrchestrator::test_orchestrator_step_tracking PASSED [ 58%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_import_chain_of_thought_module PASSED [ 59%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_chain_initialization PASSED [ 60%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_simple_reasoning_chain PASSED [ 62%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_step_by_step_decomposition PASSED [ 63%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_reasoning_step_execution PASSED [ 64%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_reasoning_chain_with_dependencies PASSED [ 66%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_iterative_refinement PASSED [ 67%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_confidence_scoring PASSED [ 68%]\ntests/test_reasoning_engine_comprehensive.py::TestChainOfThought::test_reasoning_explanation_generation PASSED [ 70%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_import_context_management_module PASSED [ 71%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_manager_initialization PASSED [ 72%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_window_calculation PASSED [ 74%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_prioritization PASSED [ 75%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_truncation PASSED [ 77%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_sliding_window_context PASSED [ 78%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_compression PASSED [ 79%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_context_relevance_scoring PASSED [ 81%]\ntests/test_reasoning_engine_comprehensive.py::TestContextManagement::test_dynamic_context_adjustment PASSED [ 82%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_import_knowledge_synthesis_module PASSED [ 83%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_synthesizer_initialization PASSED [ 85%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_multi_source_synthesis PASSED [ 86%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_conflicting_information_resolution PASSED [ 87%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_information_gap_identification PASSED [ 89%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_confidence_weighted_synthesis PASSED [ 90%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_temporal_information_synthesis PASSED [ 91%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_hierarchical_knowledge_integration PASSED [ 93%]\ntests/test_reasoning_engine_comprehensive.py::TestKnowledgeSynthesis::test_synthesis_quality_assessment PASSED [ 94%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningEngineIntegration::test_orchestrator_with_chain_of_thought PASSED [ 95%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningEngineIntegration::test_context_management_with_synthesis PASSED [ 97%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningEngineIntegration::test_end_to_end_reasoning_workflow PASSED [ 98%]\ntests/test_reasoning_engine_comprehensive.py::TestReasoningEngineIntegration::test_reasoning_with_performance_monitoring PASSED [100%]WARNING: Failed to generate report: No data to report.\n\n\n\n=================================== FAILURES ===================================\n________________ TestCustomExceptions.test_pdf_processing_error ________________\n\nself = <test_utils_comprehensive.TestCustomExceptions object at 0x7f51513a0580>\n\n    def test_pdf_processing_error(self):\n        \"\"\"Test PDF processing specific exception.\"\"\"\n        try:\n            from utils.exceptions import PDFProcessingError\n    \n>           error = PDFProcessingError(\"PDF extraction failed\", file_path=\"/test/file.pdf\")\nE           TypeError: __init__() got an unexpected keyword argument 'file_path'\n\ntests/test_utils_comprehensive.py:62: TypeError\n_____________ TestCustomExceptions.test_embedding_generation_error _____________\n\nself = <test_utils_comprehensive.TestCustomExceptions object at 0x7f51513a0730>\n\n    def test_embedding_generation_error(self):\n        \"\"\"Test embedding generation specific exception.\"\"\"\n        try:\n            from utils.exceptions import EmbeddingGenerationError\n    \n>           error = EmbeddingGenerationError(\"Embedding failed\", model=\"test-model\")\nE           TypeError: __init__() got an unexpected keyword argument 'model'\n\ntests/test_utils_comprehensive.py:72: TypeError\n___________________ TestCustomExceptions.test_database_error ___________________\n\nself = <test_utils_comprehensive.TestCustomExceptions object at 0x7f51513a08e0>\n\n    def test_database_error(self):\n        \"\"\"Test database specific exception.\"\"\"\n        try:\n            from utils.exceptions import DatabaseError\n    \n>           error = DatabaseError(\"Connection failed\", operation=\"insert\")\nE           TypeError: __init__() got an unexpected keyword argument 'operation'\n\ntests/test_utils_comprehensive.py:82: TypeError\n___________ TestMonitoringUtils.test_performance_decorator_with_name ___________\n\nself = <test_utils_comprehensive.TestMonitoringUtils object at 0x7f51513a0e80>\n\n    def test_performance_decorator_with_name(self):\n        \"\"\"Test performance decorator with custom name.\"\"\"\n        try:\n            from utils.monitoring import monitor_performance\n    \n>           @monitor_performance(operation_name=\"custom_operation\")\nE           TypeError: monitor_performance() got an unexpected keyword argument 'operation_name'\n\ntests/test_utils_comprehensive.py:134: TypeError\n_____________ TestMonitoringUtils.test_performance_timing_accuracy _____________\n\noperation_name = 'accuracy_test'\n\n    @contextmanager\n    def performance_context(operation_name: str):\n        \"\"\"Context manager for monitoring performance of code blocks.\n    \n        Args:\n            operation_name: Name of the operation being monitored\n    \n        Example:\n            with performance_context(\"database_query\"):\n                results = execute_complex_query()\n        \"\"\"\n        start_time = time.time()\n    \n        if PROMETHEUS_AVAILABLE:\n            ACTIVE_OPERATIONS.labels(operation_type=operation_name).inc()\n    \n        try:\n            logger.info(f\"Starting operation: {operation_name}\")\n            yield\n    \n            # Record success\n            duration = time.time() - start_time\n            logger.info(f\"Completed operation: {operation_name} in {duration:.3f}s\")\n    \n            if PROMETHEUS_AVAILABLE:\n>               OPERATION_COUNTER.labels(\n                    operation_type=operation_name,\n                    status=\"success\"\n                ).inc()\n\nutils/monitoring.py:127: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n../../.local/lib/python3.9/site-packages/prometheus_client/metrics.py:190: in labels\n    self._metrics[labelvalues] = self.__class__(\n../../.local/lib/python3.9/site-packages/prometheus_client/metrics.py:138: in __init__\n    self._metric_init()\n../../.local/lib/python3.9/site-packages/prometheus_client/metrics.py:279: in _metric_init\n    self._created = time.time()\n/usr/lib64/python3.9/unittest/mock.py:1092: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib64/python3.9/unittest/mock.py:1096: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <MagicMock name='time' id='139987223158064'>, args = (), kwargs = {}\neffect = <list_iterator object at 0x7f5150b629a0>\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n    \n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n>               result = next(effect)\nE               StopIteration\n\n/usr/lib64/python3.9/unittest/mock.py:1153: StopIteration\n\nDuring handling of the above exception, another exception occurred:\n\noperation_name = 'accuracy_test'\n\n    @contextmanager\n    def performance_context(operation_name: str):\n        \"\"\"Context manager for monitoring performance of code blocks.\n    \n        Args:\n            operation_name: Name of the operation being monitored\n    \n        Example:\n            with performance_context(\"database_query\"):\n                results = execute_complex_query()\n        \"\"\"\n        start_time = time.time()\n    \n        if PROMETHEUS_AVAILABLE:\n            ACTIVE_OPERATIONS.labels(operation_type=operation_name).inc()\n    \n        try:\n            logger.info(f\"Starting operation: {operation_name}\")\n            yield\n    \n            # Record success\n            duration = time.time() - start_time\n            logger.info(f\"Completed operation: {operation_name} in {duration:.3f}s\")\n    \n            if PROMETHEUS_AVAILABLE:\n                OPERATION_COUNTER.labels(\n                    operation_type=operation_name,\n                    status=\"success\"\n                ).inc()\n                OPERATION_DURATION.labels(operation_type=operation_name).observe(duration)\n    \n        except Exception as e:\n            # Record failure\n>           duration = time.time() - start_time\n\nutils/monitoring.py:135: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/usr/lib64/python3.9/unittest/mock.py:1092: in __call__\n    return self._mock_call(*args, **kwargs)\n/usr/lib64/python3.9/unittest/mock.py:1096: in _mock_call\n    return self._execute_mock_call(*args, **kwargs)\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <MagicMock name='time' id='139987223158064'>, args = (), kwargs = {}\neffect = <list_iterator object at 0x7f5150b629a0>\n\n    def _execute_mock_call(self, /, *args, **kwargs):\n        # separate from _increment_mock_call so that awaited functions are\n        # executed separately from their call, also AsyncMock overrides this method\n    \n        effect = self.side_effect\n        if effect is not None:\n            if _is_exception(effect):\n                raise effect\n            elif not _callable(effect):\n>               result = next(effect)\nE               StopIteration\n\n/usr/lib64/python3.9/unittest/mock.py:1153: StopIteration\n\nThe above exception was the direct cause of the following exception:\n\nself = <test_utils_comprehensive.TestMonitoringUtils object at 0x7f5151331550>\nmock_time = <MagicMock name='time' id='139987223158064'>\n\n    @patch('time.time')\n    def test_performance_timing_accuracy(self, mock_time):\n        \"\"\"Test performance timing accuracy.\"\"\"\n        try:\n            from utils.monitoring import performance_context\n    \n            # Mock time progression\n            mock_time.side_effect = [1000.0, 1001.5]  # 1.5 second difference\n    \n            with performance_context(\"accuracy_test\") as ctx:\n>               pass\n\ntests/test_utils_comprehensive.py:195: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <contextlib._GeneratorContextManager object at 0x7f5150b59dc0>\ntyp = None, value = None, traceback = None\n\n    def __exit__(self, typ, value, traceback):\n        if typ is None:\n            try:\n>               next(self.gen)\nE               RuntimeError: generator raised StopIteration\n\n/usr/lib64/python3.9/contextlib.py:126: RuntimeError\n____________ TestLoggingConfiguration.test_setup_logging_with_level ____________\n\nself = <test_utils_comprehensive.TestLoggingConfiguration object at 0x7f515133a2b0>\n\n    def test_setup_logging_with_level(self):\n        \"\"\"Test logging setup with specific level.\"\"\"\n        try:\n            from utils.logging_config import setup_logging\n    \n>           logger = setup_logging(\"test_service\", level=logging.DEBUG)\nE           TypeError: setup_logging() got an unexpected keyword argument 'level'\n\ntests/test_utils_comprehensive.py:375: TypeError\n___________ TestLoggingConfiguration.test_log_rotation_configuration ___________\n\nself = <test_utils_comprehensive.TestLoggingConfiguration object at 0x7f515133ab20>\n\n    def test_log_rotation_configuration(self):\n        \"\"\"Test log rotation configuration.\"\"\"\n        try:\n            from utils.logging_config import setup_logging\n    \n>           logger = setup_logging(\n                \"test_service\",\n                log_file=\"test.log\",\n                max_bytes=1024*1024,\n                backup_count=5\n            )\nE           TypeError: setup_logging() got an unexpected keyword argument 'max_bytes'\n\ntests/test_utils_comprehensive.py:462: TypeError\n___________ TestLoggingConfiguration.test_logging_performance_impact ___________\n\nself = <test_utils_comprehensive.TestLoggingConfiguration object at 0x7f515133acd0>\n\n    def test_logging_performance_impact(self):\n        \"\"\"Test logging performance impact measurement.\"\"\"\n        try:\n            from utils.logging_config import setup_logging\n    \n>           logger = setup_logging(\"test_service\", level=logging.INFO)\nE           TypeError: setup_logging() got an unexpected keyword argument 'level'\n\ntests/test_utils_comprehensive.py:479: TypeError\n\n---------- coverage: platform linux, python 3.9.21-final-0 -----------\n\n=========================== short test summary info ============================\nFAILED tests/test_utils_comprehensive.py::TestCustomExceptions::test_pdf_processing_error\nFAILED tests/test_utils_comprehensive.py::TestCustomExceptions::test_embedding_generation_error\nFAILED tests/test_utils_comprehensive.py::TestCustomExceptions::test_database_error\nFAILED tests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_decorator_with_name\nFAILED tests/test_utils_comprehensive.py::TestMonitoringUtils::test_performance_timing_accuracy\nFAILED tests/test_utils_comprehensive.py::TestLoggingConfiguration::test_setup_logging_with_level\nFAILED tests/test_utils_comprehensive.py::TestLoggingConfiguration::test_log_rotation_configuration\nFAILED tests/test_utils_comprehensive.py::TestLoggingConfiguration::test_logging_performance_impact\n========================= 8 failed, 66 passed in 0.66s =========================\n",
      "stderr": "/home/kmccullor/.local/lib/python3.9/site-packages/coverage/inorout.py:521: CoverageWarning: Module phase4a_document_classification was never imported. (module-not-imported)\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/home/kmccullor/.local/lib/python3.9/site-packages/coverage/inorout.py:521: CoverageWarning: Module phase4a_knowledge_extraction was never imported. (module-not-imported)\n  self.warn(f\"Module {pkg} was never imported.\", slug=\"module-not-imported\")\n/home/kmccullor/.local/lib/python3.9/site-packages/coverage/control.py:945: CoverageWarning: No data was collected. (no-data-collected)\n  self._warn(\"No data was collected.\", slug=\"no-data-collected\")\n/home/kmccullor/.local/lib/python3.9/site-packages/pytest_cov/plugin.py:339: CovReportWarning: Failed to generate report: No data to report.\n\n  self.cov_controller.finish()\n",
      "return_code": 1
    }
  },
  "summary": {
    "overall_success": true,
    "total_rings": 3,
    "successful_rings": 3,
    "total_tests": 121,
    "total_passed": 113,
    "total_failed": 0,
    "pass_rate": 93.38842975206612,
    "total_duration": 6.988315105438232,
    "rings_tested": [
      1,
      2,
      3
    ]
  },
  "performance": null
}