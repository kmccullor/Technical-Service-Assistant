#!/usr/bin/env python3
"""
Intelligent Test Generation and Coverage Expansion System

Advanced test automation system that provides:
- Automated test generation based on code analysis
- Intelligent coverage gap detection and filling
- AI-powered test case creation with realistic scenarios
- Dynamic test expansion based on code changes
- Smart test maintenance and optimization

Usage:
    python test_generator.py --analyze                     # Analyze coverage gaps
    python test_generator.py --generate --module utils/    # Generate tests for module
    python test_generator.py --expand --ring 2             # Expand existing ring coverage
    python test_generator.py --optimize                    # Optimize existing tests
    python test_generator.py --ai-generate --scenario api  # AI-powered test generation
"""

import ast
import os
import sys
import json
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple, Any
from datetime import datetime
import importlib.util
import inspect
import re


class CodeAnalyzer:
    """Analyze code structure and identify testing opportunities."""
    
    def __init__(self, project_root: str = "."):
        """Initialize code analyzer with project root."""
        self.project_root = Path(project_root)
        self.python_files = []
        self.function_inventory = {}
        self.class_inventory = {}
        self.coverage_gaps = {}
    
    def scan_project_structure(self) -> Dict:
        """Scan project structure and identify Python modules."""
        print("🔍 Scanning project structure for testable code...")
        
        # Find all Python files
        self.python_files = list(self.project_root.rglob("*.py"))
        
        # Exclude certain directories
        excluded_dirs = {'.venv', 'venv', '__pycache__', '.git', 'tests', 'backup'}
        self.python_files = [
            f for f in self.python_files 
            if not any(excluded in str(f) for excluded in excluded_dirs)
        ]
        
        print(f"📁 Found {len(self.python_files)} Python files for analysis")
        
        structure = {
            "total_files": len(self.python_files),
            "modules": {},
            "testable_functions": 0,
            "testable_classes": 0
        }
        
        # Analyze each file
        for py_file in self.python_files:
            try:
                module_info = self.analyze_python_file(py_file)
                if module_info:
                    relative_path = py_file.relative_to(self.project_root)
                    structure["modules"][str(relative_path)] = module_info
                    structure["testable_functions"] += len(module_info.get("functions", []))
                    structure["testable_classes"] += len(module_info.get("classes", []))
            except Exception as e:
                print(f"⚠️  Error analyzing {py_file}: {e}")
        
        return structure
    
    def analyze_python_file(self, file_path: Path) -> Optional[Dict]:
        """Analyze a single Python file for testable components."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse AST
            tree = ast.parse(content)
            
            module_info = {
                "file_path": str(file_path),
                "functions": [],
                "classes": [],
                "imports": [],
                "complexity_score": 0
            }
            
            # Analyze AST nodes
            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    func_info = self.analyze_function(node)
                    if func_info and not func_info["name"].startswith("_"):  # Skip private functions
                        module_info["functions"].append(func_info)
                
                elif isinstance(node, ast.ClassDef):
                    class_info = self.analyze_class(node)
                    if class_info:
                        module_info["classes"].append(class_info)
                
                elif isinstance(node, (ast.Import, ast.ImportFrom)):
                    import_info = self.analyze_import(node)
                    if import_info:
                        module_info["imports"].extend(import_info)
            
            # Calculate complexity score
            module_info["complexity_score"] = self.calculate_complexity_score(module_info)
            
            return module_info
            
        except Exception as e:
            print(f"❌ Error parsing {file_path}: {e}")
            return None
    
    def analyze_function(self, node: ast.FunctionDef) -> Dict:
        """Analyze function for test generation potential."""
        return {
            "name": node.name,
            "line_number": node.lineno,
            "args": [arg.arg for arg in node.args.args],
            "returns_value": any(isinstance(n, ast.Return) for n in ast.walk(node)),
            "has_docstring": ast.get_docstring(node) is not None,
            "complexity": len([n for n in ast.walk(node) if isinstance(n, (ast.If, ast.For, ast.While, ast.Try))]),
            "async": isinstance(node, ast.AsyncFunctionDef),
            "decorators": [d.id if isinstance(d, ast.Name) else str(d) for d in node.decorator_list]
        }
    
    def analyze_class(self, node: ast.ClassDef) -> Dict:
        """Analyze class for test generation potential."""
        methods = [n for n in node.body if isinstance(n, ast.FunctionDef)]
        
        return {
            "name": node.name,
            "line_number": node.lineno,
            "methods": [self.analyze_function(method) for method in methods],
            "has_init": any(method.name == "__init__" for method in methods),
            "base_classes": [base.id if isinstance(base, ast.Name) else str(base) for base in node.bases],
            "decorators": [d.id if isinstance(d, ast.Name) else str(d) for d in node.decorator_list]
        }
    
    def analyze_import(self, node) -> List[str]:
        """Analyze imports for dependency tracking."""
        imports = []
        
        if isinstance(node, ast.Import):
            for alias in node.names:
                imports.append(alias.name)
        elif isinstance(node, ast.ImportFrom):
            module = node.module or ""
            for alias in node.names:
                imports.append(f"{module}.{alias.name}")
        
        return imports
    
    def calculate_complexity_score(self, module_info: Dict) -> int:
        """Calculate module complexity score for test prioritization."""
        score = 0
        
        # Function complexity
        for func in module_info.get("functions", []):
            score += func.get("complexity", 0) * 2  # Weight function complexity highly
            score += len(func.get("args", [])) * 1  # More args = more test cases needed
        
        # Class complexity  
        for cls in module_info.get("classes", []):
            score += len(cls.get("methods", [])) * 3  # Classes with many methods need more tests
            if cls.get("has_init"):
                score += 5  # Constructor needs testing
        
        return score
    
    def identify_coverage_gaps(self, existing_tests_dir: str = "tests") -> Dict:
        """Identify gaps in test coverage by comparing code to existing tests."""
        print("📊 Identifying coverage gaps...")
        
        # Get existing test files
        tests_path = Path(existing_tests_dir)
        existing_tests = list(tests_path.glob("test_*.py")) if tests_path.exists() else []
        
        print(f"📋 Found {len(existing_tests)} existing test files")
        
        gaps = {
            "untested_modules": [],
            "untested_functions": [],
            "untested_classes": [],
            "low_coverage_modules": [],
            "priority_gaps": []
        }
        
        # Analyze each module for test coverage
        for module_path, module_info in self.scan_project_structure()["modules"].items():
            # Check if module has corresponding test file
            module_name = Path(module_path).stem
            test_file_patterns = [
                f"test_{module_name}.py",
                f"test_{module_name}_*.py",
                f"*_{module_name}_test.py"
            ]
            
            has_tests = any(
                any(test_file.match(pattern) for pattern in test_file_patterns)
                for test_file in existing_tests
            )
            
            if not has_tests:
                gaps["untested_modules"].append({
                    "module": module_path,
                    "complexity": module_info["complexity_score"],
                    "functions": len(module_info["functions"]),
                    "classes": len(module_info["classes"])
                })
            
            # Identify untested functions and classes
            for func in module_info.get("functions", []):
                if func["complexity"] > 2:  # Complex functions need tests
                    gaps["untested_functions"].append({
                        "module": module_path,
                        "function": func["name"],
                        "complexity": func["complexity"],
                        "args": func["args"]
                    })
            
            for cls in module_info.get("classes", []):
                if len(cls["methods"]) > 2:  # Classes with multiple methods need tests
                    gaps["untested_classes"].append({
                        "module": module_path,
                        "class": cls["name"],
                        "methods": len(cls["methods"]),
                        "has_init": cls["has_init"]
                    })
        
        # Prioritize gaps by complexity and importance
        gaps["priority_gaps"] = self._prioritize_coverage_gaps(gaps)
        
        return gaps
    
    def _prioritize_coverage_gaps(self, gaps: Dict) -> List[Dict]:
        """Prioritize coverage gaps by importance and complexity."""
        priority_items = []
        
        # High priority: complex untested modules
        for module in gaps["untested_modules"]:
            if module["complexity"] > 10:
                priority_items.append({
                    "type": "module",
                    "priority": "high", 
                    "item": module,
                    "reason": "High complexity module without tests"
                })
        
        # Medium priority: untested functions with complexity
        for func in gaps["untested_functions"]:
            if func["complexity"] > 3:
                priority_items.append({
                    "type": "function",
                    "priority": "medium",
                    "item": func,
                    "reason": "Complex function needs comprehensive testing"
                })
        
        # Sort by priority and complexity
        priority_order = {"high": 3, "medium": 2, "low": 1}
        priority_items.sort(
            key=lambda x: (priority_order.get(x["priority"], 0), x["item"].get("complexity", 0)),
            reverse=True
        )
        
        return priority_items[:20]  # Return top 20 priority items


class TestGenerator:
    """Generate comprehensive tests based on code analysis."""
    
    def __init__(self, analyzer: CodeAnalyzer):
        """Initialize test generator with code analyzer."""
        self.analyzer = analyzer
        self.test_templates = self.load_test_templates()
    
    def load_test_templates(self) -> Dict:
        """Load test templates for different code patterns."""
        return {
            "function_basic": '''
def test_{function_name}_basic(self):
    """Test basic functionality of {function_name}."""
    # Arrange
    {arrange_code}
    
    # Act
    result = {function_call}
    
    # Assert
    assert result is not None
    {additional_assertions}
''',
            "function_with_args": '''
def test_{function_name}_with_valid_args(self):
    """Test {function_name} with valid arguments."""
    # Arrange
    {test_args}
    
    # Act
    result = {function_call}
    
    # Assert
    {assertions}

def test_{function_name}_with_invalid_args(self):
    """Test {function_name} with invalid arguments."""
    with pytest.raises({expected_exception}):
        {function_call_invalid}
''',
            "class_basic": '''
class Test{class_name}:
    """Test suite for {class_name} class."""
    
    @pytest.fixture
    def {fixture_name}(self):
        """Create {class_name} instance for testing."""
        return {class_name}({init_args})
    
    def test_{class_name_lower}_initialization(self, {fixture_name}):
        """Test {class_name} initialization."""
        assert isinstance({fixture_name}, {class_name})
        {init_assertions}
    
    {method_tests}
''',
            "async_function": '''
@pytest.mark.asyncio
async def test_{function_name}_async(self):
    """Test async {function_name} functionality."""
    # Arrange
    {arrange_code}
    
    # Act
    result = await {function_call}
    
    # Assert
    assert result is not None
    {async_assertions}
''',
            "error_handling": '''
def test_{function_name}_error_handling(self):
    """Test {function_name} error handling."""
    with pytest.raises({exception_type}):
        {error_triggering_call}
    
def test_{function_name}_edge_cases(self):
    """Test {function_name} with edge cases."""
    # Test empty input
    result = {function_name}({empty_args})
    assert {empty_assertion}
    
    # Test boundary values
    {boundary_tests}
'''
        }
    
    def generate_tests_for_module(self, module_path: str, output_dir: str = "tests") -> str:
        """Generate comprehensive tests for a specific module."""
        print(f"🧪 Generating tests for module: {module_path}")
        
        # Analyze the module
        module_file = Path(module_path)
        if not module_file.exists():
            print(f"❌ Module file not found: {module_path}")
            return ""
        
        module_info = self.analyzer.analyze_python_file(module_file)
        if not module_info:
            print(f"❌ Could not analyze module: {module_path}")
            return ""
        
        # Generate test file content
        test_content = self.create_test_file_header(module_path)
        
        # Generate tests for functions
        for func_info in module_info.get("functions", []):
            test_content += self.generate_function_tests(func_info, module_path)
        
        # Generate tests for classes
        for class_info in module_info.get("classes", []):
            test_content += self.generate_class_tests(class_info, module_path)
        
        # Write test file
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)
        
        module_name = module_file.stem
        test_file_path = output_path / f"test_{module_name}_generated.py"
        
        with open(test_file_path, 'w') as f:
            f.write(test_content)
        
        print(f"✅ Generated test file: {test_file_path}")
        return str(test_file_path)
    
    def create_test_file_header(self, module_path: str) -> str:
        """Create test file header with imports and metadata."""
        module_name = Path(module_path).stem
        relative_import = str(Path(module_path)).replace('/', '.').replace('.py', '')
        
        header = f'''"""
Generated Test Suite for {module_name}

Auto-generated comprehensive tests covering functions, classes, and edge cases.
Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Source module: {module_path}
"""

import pytest
from unittest.mock import Mock, patch, MagicMock
from typing import Any, Dict, List, Optional
import sys
import os

# Add project root to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from {relative_import} import *
except ImportError as e:
    # Fallback import strategy
    import importlib.util
    spec = importlib.util.spec_from_file_location("{module_name}", "{module_path}")
    if spec and spec.loader:
        module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(module)
        globals().update({{name: getattr(module, name) for name in dir(module) if not name.startswith('_')}})
    else:
        pytest.skip(f"Could not import module: {{e}}")


'''
        return header
    
    def generate_function_tests(self, func_info: Dict, module_path: str) -> str:
        """Generate comprehensive tests for a function."""
        func_name = func_info["name"]
        args = func_info["args"]
        complexity = func_info["complexity"]
        is_async = func_info["async"]
        
        tests = f"\n# Tests for {func_name}\n"
        
        # Basic functionality test
        if is_async:
            template = self.test_templates["async_function"]
        else:
            template = self.test_templates["function_basic"]
        
        arrange_code = self.generate_arrange_code(args)
        function_call = self.generate_function_call(func_name, args)
        
        tests += template.format(
            function_name=func_name,
            arrange_code=arrange_code,
            function_call=function_call,
            additional_assertions=self.generate_basic_assertions(func_info),
            async_assertions="# Add specific async assertions here"
        )
        
        # Tests with arguments
        if args:
            tests += self.test_templates["function_with_args"].format(
                function_name=func_name,
                test_args=self.generate_test_args(args),
                function_call=function_call,
                assertions=self.generate_argument_assertions(args),
                expected_exception="ValueError",  # Default exception
                function_call_invalid=self.generate_invalid_function_call(func_name, args)
            )
        
        # Error handling tests for complex functions
        if complexity > 1:
            tests += self.test_templates["error_handling"].format(
                function_name=func_name,
                exception_type="Exception",
                error_triggering_call=self.generate_error_triggering_call(func_name, args),
                empty_args=self.generate_empty_args(args),
                empty_assertion="result is not None",
                boundary_tests=self.generate_boundary_tests(func_name, args)
            )
        
        return tests
    
    def generate_class_tests(self, class_info: Dict, module_path: str) -> str:
        """Generate comprehensive tests for a class."""
        class_name = class_info["name"]
        methods = class_info["methods"]
        has_init = class_info["has_init"]
        
        tests = f"\n# Tests for {class_name} class\n"
        
        # Find __init__ method for initialization tests
        init_method = next((m for m in methods if m["name"] == "__init__"), None)
        init_args = init_method["args"][1:] if init_method else []  # Skip 'self'
        
        # Generate method tests
        method_tests = ""
        for method in methods:
            if method["name"] not in ["__init__", "__str__", "__repr__"]:
                method_tests += self.generate_method_test(method, class_name)
        
        tests += self.test_templates["class_basic"].format(
            class_name=class_name,
            fixture_name=f"{class_name.lower()}_instance",
            init_args=self.generate_init_args(init_args),
            class_name_lower=class_name.lower(),
            init_assertions=self.generate_init_assertions(init_args),
            method_tests=method_tests
        )
        
        return tests
    
    def generate_method_test(self, method_info: Dict, class_name: str) -> str:
        """Generate test for a class method."""
        method_name = method_info["name"]
        args = method_info["args"][1:]  # Skip 'self'
        
        return f'''
    def test_{method_name}(self, {class_name.lower()}_instance):
        """Test {class_name}.{method_name} method."""
        # Arrange
        {self.generate_arrange_code(args)}
        
        # Act
        result = {class_name.lower()}_instance.{method_name}({self.generate_args_call(args)})
        
        # Assert
        assert result is not None
        # Add specific assertions for {method_name}
'''
    
    def generate_arrange_code(self, args: List[str]) -> str:
        """Generate arrange section code for test arguments."""
        if not args:
            return "# No arguments required"
        
        arrange_lines = []
        for arg in args:
            if "path" in arg.lower() or "file" in arg.lower():
                arrange_lines.append(f'{arg} = "test_file.txt"')
            elif "id" in arg.lower():
                arrange_lines.append(f'{arg} = 1')
            elif "name" in arg.lower():
                arrange_lines.append(f'{arg} = "test_name"')
            elif "data" in arg.lower():
                arrange_lines.append(f'{arg} = {{"test": "data"}}')
            elif "list" in arg.lower():
                arrange_lines.append(f'{arg} = ["item1", "item2"]')
            else:
                arrange_lines.append(f'{arg} = "test_value"')
        
        return "\n    ".join(arrange_lines)
    
    def generate_function_call(self, func_name: str, args: List[str]) -> str:
        """Generate function call with appropriate arguments."""
        if not args:
            return f"{func_name}()"
        
        arg_names = ", ".join(args)
        return f"{func_name}({arg_names})"
    
    def generate_args_call(self, args: List[str]) -> str:
        """Generate argument call string."""
        return ", ".join(args) if args else ""
    
    def generate_basic_assertions(self, func_info: Dict) -> str:
        """Generate basic assertions based on function characteristics."""
        assertions = []
        
        if func_info.get("returns_value", True):
            assertions.append("# Verify result is of expected type")
        
        if func_info.get("complexity", 0) > 2:
            assertions.append("# Add assertions for complex logic paths")
        
        return "\n    ".join(assertions) if assertions else "# Add specific assertions here"
    
    def generate_test_args(self, args: List[str]) -> str:
        """Generate test argument assignments."""
        return self.generate_arrange_code(args)
    
    def generate_argument_assertions(self, args: List[str]) -> str:
        """Generate assertions for testing with arguments."""
        return f"assert result is not None  # Verify function executes with {len(args)} arguments"
    
    def generate_invalid_function_call(self, func_name: str, args: List[str]) -> str:
        """Generate function call with invalid arguments."""
        invalid_args = ", ".join("None" for _ in args)
        return f"{func_name}({invalid_args})"
    
    def generate_error_triggering_call(self, func_name: str, args: List[str]) -> str:
        """Generate function call that should trigger an error."""
        return self.generate_invalid_function_call(func_name, args)
    
    def generate_empty_args(self, args: List[str]) -> str:
        """Generate empty/default arguments."""
        if not args:
            return ""
        return ", ".join('""' if i == 0 else "None" for i in range(len(args)))
    
    def generate_boundary_tests(self, func_name: str, args: List[str]) -> str:
        """Generate boundary value tests."""
        if not args:
            return "# No boundary tests for functions without arguments"
        
        return f"""# Test with very large values
    result_large = {func_name}({", ".join('"x" * 1000' if "str" in arg else "999999" for arg in args)})
    
    # Test with very small values  
    result_small = {func_name}({", ".join('""' if "str" in arg else "0" for arg in args)})"""
    
    def generate_init_args(self, args: List[str]) -> str:
        """Generate initialization arguments for class constructor."""
        if not args:
            return ""
        
        init_values = []
        for arg in args:
            if "config" in arg.lower():
                init_values.append('{"test": "config"}')
            elif "path" in arg.lower():
                init_values.append('"test_path"')
            else:
                init_values.append('"test_value"')
        
        return ", ".join(init_values)
    
    def generate_init_assertions(self, args: List[str]) -> str:
        """Generate assertions for class initialization."""
        if not args:
            return "# Class initialized successfully"
        
        assertions = []
        for arg in args:
            assertions.append(f"# Verify {arg} was set correctly")
        
        return "\n        ".join(assertions)
    
    def prioritize_coverage_gaps(self, gaps: Dict) -> List[Dict]:
        """Prioritize coverage gaps by importance and complexity."""
        priority_items = []
        
        # High priority: complex untested modules
        for module in gaps["untested_modules"]:
            if module["complexity"] > 10:
                priority_items.append({
                    "type": "module",
                    "priority": "high",
                    "item": module,
                    "reason": "High complexity module without tests"
                })
        
        # Medium priority: untested functions with complexity
        for func in gaps["untested_functions"]:
            if func["complexity"] > 3:
                priority_items.append({
                    "type": "function", 
                    "priority": "medium",
                    "item": func,
                    "reason": "Complex function needs comprehensive testing"
                })
        
        # Sort by priority and complexity
        priority_order = {"high": 3, "medium": 2, "low": 1}
        priority_items.sort(
            key=lambda x: (priority_order.get(x["priority"], 0), x["item"].get("complexity", 0)),
            reverse=True
        )
        
        return priority_items[:20]  # Return top 20 priority items


class IntelligentTestExpander:
    """Expand existing test suites with intelligent coverage improvements."""
    
    def __init__(self, analyzer: CodeAnalyzer, generator: TestGenerator):
        """Initialize test expander with analyzer and generator."""
        self.analyzer = analyzer
        self.generator = generator
    
    def expand_ring_coverage(self, ring_id: int) -> Dict:
        """Expand test coverage for a specific ring."""
        print(f"🔄 Expanding test coverage for Ring {ring_id}...")
        
        ring_modules = self.get_ring_modules(ring_id)
        expansion_results = {
            "ring_id": ring_id,
            "modules_analyzed": len(ring_modules),
            "tests_generated": 0,
            "coverage_improvements": []
        }
        
        for module_path in ring_modules:
            try:
                # Analyze current coverage
                coverage_analysis = self.analyze_current_coverage(module_path)
                
                # Generate additional tests
                if coverage_analysis["gaps"]:
                    test_file = self.generator.generate_tests_for_module(module_path)
                    expansion_results["tests_generated"] += coverage_analysis["potential_tests"]
                    expansion_results["coverage_improvements"].append({
                        "module": module_path,
                        "test_file": test_file,
                        "gaps_filled": len(coverage_analysis["gaps"])
                    })
            
            except Exception as e:
                print(f"⚠️  Error expanding coverage for {module_path}: {e}")
        
        return expansion_results
    
    def get_ring_modules(self, ring_id: int) -> List[str]:
        """Get list of modules for a specific ring."""
        ring_mappings = {
            1: ["phase4a_document_classification.py", "phase4a_knowledge_extraction.py"],
            2: ["pdf_processor/utils.py", "pdf_processor/pdf_utils.py"], 
            3: ["utils/", "reasoning_engine/", "reranker/"]
        }
        
        modules = ring_mappings.get(ring_id, [])
        expanded_modules = []
        
        for module in modules:
            if module.endswith('/'):
                # Directory - find all Python files
                module_dir = Path(module)
                if module_dir.exists():
                    expanded_modules.extend(str(f) for f in module_dir.rglob("*.py"))
            else:
                # Single file
                if Path(module).exists():
                    expanded_modules.append(module)
        
        return expanded_modules
    
    def analyze_current_coverage(self, module_path: str) -> Dict:
        """Analyze current test coverage for a module."""
        module_info = self.analyzer.analyze_python_file(Path(module_path))
        if not module_info:
            return {"gaps": [], "potential_tests": 0}
        
        # Simple gap analysis - in practice, this could integrate with coverage.py
        gaps = []
        potential_tests = 0
        
        for func in module_info.get("functions", []):
            if func["complexity"] > 1:
                gaps.append({"type": "function", "name": func["name"], "complexity": func["complexity"]})
                potential_tests += func["complexity"] * 2  # Estimate tests needed
        
        for cls in module_info.get("classes", []):
            if len(cls["methods"]) > 2:
                gaps.append({"type": "class", "name": cls["name"], "methods": len(cls["methods"])})
                potential_tests += len(cls["methods"]) * 3  # Estimate tests needed
        
        return {"gaps": gaps, "potential_tests": potential_tests}


def main():
    """Main entry point for intelligent test generation system."""
    parser = argparse.ArgumentParser(description="Intelligent Test Generation and Coverage Expansion")
    parser.add_argument("--analyze", action="store_true", help="Analyze project structure and coverage gaps")
    parser.add_argument("--generate", action="store_true", help="Generate tests for specified module")
    parser.add_argument("--module", type=str, help="Module path for test generation")
    parser.add_argument("--expand", action="store_true", help="Expand existing ring coverage")
    parser.add_argument("--ring", type=int, choices=[1, 2, 3], help="Ring ID for expansion")
    parser.add_argument("--optimize", action="store_true", help="Optimize existing test suites")
    parser.add_argument("--output", type=str, default="tests", help="Output directory for generated tests")
    
    args = parser.parse_args()
    
    # Initialize components
    analyzer = CodeAnalyzer()
    generator = TestGenerator(analyzer)
    expander = IntelligentTestExpander(analyzer, generator)
    
    if args.analyze:
        print("🔍 Analyzing project structure and coverage gaps...")
        structure = analyzer.scan_project_structure()
        gaps = analyzer.identify_coverage_gaps()
        
        print(f"\n📊 Project Analysis Results:")
        print(f"   Total Python files: {structure['total_files']}")
        print(f"   Testable functions: {structure['testable_functions']}")
        print(f"   Testable classes: {structure['testable_classes']}")
        print(f"   Untested modules: {len(gaps['untested_modules'])}")
        print(f"   Priority gaps: {len(gaps['priority_gaps'])}")
        
        # Show top priority gaps
        print(f"\n🎯 Top Priority Coverage Gaps:")
        for i, gap in enumerate(gaps['priority_gaps'][:5], 1):
            item = gap['item']
            print(f"   {i}. {gap['type'].title()}: {item.get('module', item.get('function', item.get('class')))}")
            print(f"      Priority: {gap['priority'].upper()}, Complexity: {item.get('complexity', 'N/A')}")
    
    elif args.generate and args.module:
        print(f"🧪 Generating tests for module: {args.module}")
        test_file = generator.generate_tests_for_module(args.module, args.output)
        print(f"✅ Test generation complete: {test_file}")
    
    elif args.expand and args.ring:
        print(f"🔄 Expanding Ring {args.ring} test coverage...")
        results = expander.expand_ring_coverage(args.ring)
        
        print(f"\n📈 Ring {args.ring} Expansion Results:")
        print(f"   Modules analyzed: {results['modules_analyzed']}")
        print(f"   Tests generated: {results['tests_generated']}")
        print(f"   Coverage improvements: {len(results['coverage_improvements'])}")
        
        for improvement in results['coverage_improvements']:
            print(f"   - {improvement['module']}: {improvement['gaps_filled']} gaps filled")
    
    elif args.optimize:
        print("⚡ Optimizing existing test suites...")
        print("🚧 Test optimization feature coming soon!")
    
    else:
        print("Please specify --analyze, --generate --module <path>, --expand --ring <id>, or --optimize")
        sys.exit(1)


if __name__ == "__main__":
    main()